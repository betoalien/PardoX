{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e45c88-dd93-4076-925f-453421dd9b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pardoX] System Detected: Ubuntu | RAM: 13.55 GB | Cores: 8\n",
      "[pardoX] ðŸŽ® Dedicated GPU Detected: amdgpu edge\n",
      "[pardoX] Profile: Balanced (Mid-Range) | Budget: 6.10 GB | Threads: 7\n",
      "[pardoX] ðŸš€ TURBO (Async Buffer) | ChunkSize: 32 MB | QueueDepth: 39 blocks\n",
      "âœ… PardoX imported successfully.\n",
      "ðŸ“‚ Base data path: data_sales\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pardox as px\n",
    "\n",
    "# Setup paths for local data\n",
    "base_path = \"data_sales\"\n",
    "\n",
    "print(f\"âœ… PardoX imported successfully.\")\n",
    "print(f\"ðŸ“‚ Base data path: {base_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a7c260-e173-4d4e-959f-6923e08d5a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Loading: data_sales/Ventas_Baja_California_2020.csv ...\n",
      "ðŸš€ Loading: data_sales/Ventas_Baja_California_2021.csv ...\n",
      "âœ… DataFrames loaded into HyperBlock Memory.\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuration\n",
    "path_2020 = os.path.join(base_path, \"Ventas_Baja_California_2020.csv\")\n",
    "path_2021 = os.path.join(base_path, \"Ventas_Baja_California_2021.csv\")\n",
    "\n",
    "# 2. Ingestion\n",
    "# PardoX uses a multi-threaded CSV reader written in Rust.\n",
    "# If 'schema' is not provided, the 'LazyFileScanner' automatically infers data types.\n",
    "print(f\"ðŸš€ Loading: {path_2020} ...\")\n",
    "df_2020 = px.read_csv(path_2020)\n",
    "\n",
    "print(f\"ðŸš€ Loading: {path_2021} ...\")\n",
    "df_2021 = px.read_csv(path_2021)\n",
    "\n",
    "print(\"âœ… DataFrames loaded into HyperBlock Memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ad1cad-c292-49da-9615-c6cc595febdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ 2020 Shape: (2000000, 8)\n",
      "ðŸ“ 2021 Shape: (1000000, 8)\n",
      "\n",
      "ðŸ“‹ Column Types (2020):\n",
      "{'transaction_id': 'Int64', 'client_id': 'Int64', 'date_time': 'Utf8', 'entity': 'Utf8', 'category': 'Utf8', 'client_segment': 'Utf8', 'amount': 'Float64', 'tax_rate': 'Float64'}\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions (rows, columns)\n",
    "# This is an O(1) operation reading metadata from the Rust Manager.\n",
    "print(f\"ðŸ“ 2020 Shape: {df_2020.shape}\")\n",
    "print(f\"ðŸ“ 2021 Shape: {df_2021.shape}\")\n",
    "\n",
    "# Inspect Schema\n",
    "# Verifies that columns were correctly identified as Float64, Int64, or Utf8.\n",
    "print(\"\\nðŸ“‹ Column Types (2020):\")\n",
    "print(df_2020.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9deae5-845a-4d2f-ba96-85bd0d48e454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- HEAD (First 5 Rows of 2020) ---\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+\n",
      "| # | transaction_id | client_id |      date_time      |     entity      |  category   | client_segment |  amount   | tax_rate |\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+\n",
      "| 0 | 1873002        | 1230720   | 2020-05-18 07:05:29 | Baja_California | Sports      | VIP            | 3683.9500 | 0.1600   |\n",
      "| 1 | 1873003        | 9324201   | 2020-02-29 13:42:49 | Baja_California | Home_Decor  | Inactive       | 4104.0000 | 0.1600   |\n",
      "| 2 | 1873004        | 6985480   | 2020-12-01 06:48:22 | Baja_California | Garden      | Standard       | 818.1400  | 0.1600   |\n",
      "| 3 | 1873005        | 9140257   | 2020-01-17 07:58:32 | Baja_California | Electronics | Inactive       | 4362.7900 | 0.1600   |\n",
      "| 4 | 1873006        | 4952383   | 2020-12-14 23:35:34 | Baja_California | Beauty      | New            | 4917.5800 | 0.1600   |\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "\n",
      "\n",
      "--- TAIL (Last 5 Rows of 2021) ---\n",
      "+---+----------------+-----------+---------------------+-----------------+------------+----------------+------------+----------+\n",
      "| # | transaction_id | client_id |      date_time      |     entity      |  category  | client_segment |   amount   | tax_rate |\n",
      "+---+----------------+-----------+---------------------+-----------------+------------+----------------+------------+----------+\n",
      "| 0 | 2216604        | 2789405   | 2021-12-29 06:20:07 | Baja_California | Agro       | B              | 9131.3700  | 0.1600   |\n",
      "| 1 | 2216605        | 3311372   | 2021-06-02 16:09:44 | Baja_California | Mineria    | A              | 5082.9800  | 0.1600   |\n",
      "| 2 | 2216606        | 3574516   | 2021-08-12 15:07:33 | Baja_California | Industrial | VIP            | 11656.8200 | 0.1600   |\n",
      "| 3 | 2216607        | 1798018   | 2021-09-19 05:40:16 | Baja_California | Automotriz | VIP            | 11597.7900 | 0.1600   |\n",
      "| 4 | 2216608        | 1128815   | 2021-01-08 06:22:27 | Baja_California | Automotriz | A              | 9597.6600  | 0.1600   |\n",
      "+---+----------------+-----------+---------------------+-----------------+------------+----------------+------------+----------+\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Head: Returns the first N rows.\n",
    "# PardoX performs a Zero-Copy slice and formats the output using the Rust engine.\n",
    "print(\"--- HEAD (First 5 Rows of 2020) ---\")\n",
    "print(df_2020.head(5))\n",
    "\n",
    "# Tail: Returns the last N rows.\n",
    "print(\"\\n--- TAIL (Last 5 Rows of 2021) ---\")\n",
    "print(df_2021.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926b2751-b382-4e15-88c3-fa679a5cca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SLICE (Middle of Dataset) ---\n",
      "+---+----------------+-----------+---------------------+-----------------+------------+----------------+-----------+----------+\n",
      "| # | transaction_id | client_id |      date_time      |     entity      |  category  | client_segment |  amount   | tax_rate |\n",
      "+---+----------------+-----------+---------------------+-----------------+------------+----------------+-----------+----------+\n",
      "| 0 | 1501307        | 6461316   | 2020-05-24 10:53:57 | Baja_California | Grocery    | VIP            | 311.7900  | 0.1600   |\n",
      "| 1 | 1501308        | 277743    | 2020-01-02 17:30:54 | Baja_California | Grocery    | Corporate      | 4667.4400 | 0.1600   |\n",
      "| 2 | 1501309        | 5196772   | 2020-09-08 13:00:06 | Baja_California | Grocery    | VIP            | 4657.2200 | 0.1600   |\n",
      "| 3 | 1501310        | 3038542   | 2020-06-25 23:54:35 | Baja_California | Automotive | New            | 3159.0200 | 0.1600   |\n",
      "| 4 | 1501311        | 7804428   | 2020-04-08 02:36:39 | Baja_California | Automotive | Corporate      | 3948.0400 | 0.1600   |\n",
      "+---+----------------+-----------+---------------------+-----------------+------------+----------------+-----------+----------+\n",
      "\n",
      "[5 rows x 8 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Slicing with iloc\n",
    "# Access rows 1,000,000 to 1,000,005.\n",
    "# This operation uses pointer arithmetic in Rust, avoiding memory duplication.\n",
    "print(\"--- SLICE (Middle of Dataset) ---\")\n",
    "middle_slice = df_2020.iloc[1000000:1000005]\n",
    "print(middle_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e695c6-aeb7-4fcf-b250-47f8d8dbedc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§® Calculating Taxes (Amount * Tax Rate)...\n",
      "\n",
      "--- Calculation Result (IVA Series) ---\n",
      "+---+------------+\n",
      "| # | result_mul |\n",
      "+---+------------+\n",
      "| 0 | 589.4320   |\n",
      "| 1 | 656.6400   |\n",
      "| 2 | 130.9024   |\n",
      "| 3 | 698.0464   |\n",
      "| 4 | 786.8128   |\n",
      "+---+------------+\n",
      "\n",
      "[5 rows x 1 columns]\n",
      "\n",
      "\n",
      "--- Calculation Result (Total Series) ---\n",
      "+---+------------+\n",
      "| # | result_add |\n",
      "+---+------------+\n",
      "| 0 | 4273.3820  |\n",
      "| 1 | 4760.6400  |\n",
      "| 2 | 949.0424   |\n",
      "| 3 | 5060.8364  |\n",
      "| 4 | 5704.3928  |\n",
      "+---+------------+\n",
      "\n",
      "[5 rows x 1 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vectorized Arithmetic\n",
    "# Operations are routed to either CPU (SIMD/Rayon) or GPU based on dataset size.\n",
    "# Current Logic: If rows > 50M -> GPU, else -> CPU (Optimized).\n",
    "\n",
    "print(\"ðŸ§® Calculating Taxes (Amount * Tax Rate)...\")\n",
    "\n",
    "# 1. Multiplication\n",
    "iva_series = df_2020['amount'] * df_2020['tax_rate']\n",
    "\n",
    "# 2. Addition (Chained Operation)\n",
    "total_series = df_2020['amount'] + iva_series\n",
    "\n",
    "print(\"\\n--- Calculation Result (IVA Series) ---\")\n",
    "print(iva_series.head(5))\n",
    "\n",
    "print(\"\\n--- Calculation Result (Total Series) ---\")\n",
    "print(total_series.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c112bebf-9d6b-4c22-bf64-f03269a802e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§® Feature Engineering: Calculating Taxes and Totals...\n",
      "âœ… Columns 'tax_amount' and 'total_paid' added successfully.\n",
      "   New Columns: ['transaction_id', 'client_id', 'date_time', 'entity', 'category', 'client_segment', 'amount', 'tax_rate', 'tax_amount', 'total_paid']\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ§® Feature Engineering: Calculating Taxes and Totals...\")\n",
    "\n",
    "# 1. Vectorized Multiplication (SIMD)\n",
    "# We calculate the exact tax amount (Amount * Tax Rate).\n",
    "# Rust executes this using parallel AVX2 instructions.\n",
    "iva_series = df_2020['amount'] * df_2020['tax_rate']\n",
    "\n",
    "# 2. Column Assignment (In-Place Injection)\n",
    "# This is the magic: We take the floating-point result and \"inject\" it\n",
    "# into the main DataFrame using Zero-Copy mechanics.\n",
    "df_2020['tax_amount'] = iva_series\n",
    "\n",
    "# 3. Compound Calculation (Total = Amount + Tax)\n",
    "# We can immediately use the new column for further calculations.\n",
    "df_2020['total_paid'] = df_2020['amount'] + df_2020['tax_amount']\n",
    "\n",
    "print(\"âœ… Columns 'tax_amount' and 'total_paid' added successfully.\")\n",
    "print(\"   New Columns:\", df_2020.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f5ab31-9c88-4cdc-953c-738e5218c5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Final Inspection (First 5 rows with new features):\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+------------+------------+\n",
      "| # | transaction_id | client_id |      date_time      |     entity      |  category   | client_segment |  amount   | tax_rate | tax_amount | total_paid |\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+------------+------------+\n",
      "| 0 | 1873002        | 1230720   | 2020-05-18 07:05:29 | Baja_California | Sports      | VIP            | 3683.9500 | 0.1600   | 589.4320   | 4273.3820  |\n",
      "| 1 | 1873003        | 9324201   | 2020-02-29 13:42:49 | Baja_California | Home_Decor  | Inactive       | 4104.0000 | 0.1600   | 656.6400   | 4760.6400  |\n",
      "| 2 | 1873004        | 6985480   | 2020-12-01 06:48:22 | Baja_California | Garden      | Standard       | 818.1400  | 0.1600   | 130.9024   | 949.0424   |\n",
      "| 3 | 1873005        | 9140257   | 2020-01-17 07:58:32 | Baja_California | Electronics | Inactive       | 4362.7900 | 0.1600   | 698.0464   | 5060.8364  |\n",
      "| 4 | 1873006        | 4952383   | 2020-12-14 23:35:34 | Baja_California | Beauty      | New            | 4917.5800 | 0.1600   | 786.8128   | 5704.3928  |\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+------------+------------+\n",
      "\n",
      "... showing top 5 of 2000000 rows ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ” Final Inspection (First 5 rows with new features):\")\n",
    "\n",
    "# Using our native ASCII visualizer\n",
    "# You should see the new columns appended to the right.\n",
    "df_2020.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961db1fb-8e78-4e29-9f70-1870aa332565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Data Hygiene & Formatting...\n",
      "âœ¨ Data Cleaned and Rounded.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ§¹ Data Hygiene & Formatting...\")\n",
    "\n",
    "# 1. Filling Nulls (Imputation)\n",
    "# The Rust Kernel scans the Null Bitmaps at the byte level.\n",
    "# If it finds a gap in any numeric column, it fills it with 0.0\n",
    "# and instantly marks the data as valid.\n",
    "df_2020.fillna(0.0)\n",
    "\n",
    "# 2. Financial Rounding (Presentation)\n",
    "# We adjust all numeric columns to 2 decimal places to avoid\n",
    "# floating-point artifacts (e.g., 100.0000001 -> 100.00).\n",
    "df_2020.round(2)\n",
    "\n",
    "print(\"âœ¨ Data Cleaned and Rounded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "570c1a4d-975a-4f9d-9cb3-a246fe322c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¡ Connecting to: postgresql://betoalien:X6YGEM4CJkgR@ep-shiny-bread-78618702-pooler.us-east-2.aws.neon.tech/pleyades\n",
      "âœ… SQL Ingestion Complete. Rows: 3390000\n",
      "\n",
      "--- Clients Table Preview ---\n",
      "+---+-----------+-----------------+----------------------------+------------+---------------------+---------------------+---------------------+----------+--------+\n",
      "| # | client_id |    full_name    |           email            |   phone    |       address       |        city         |        state        | zip_code | status |\n",
      "+---+-----------+-----------------+----------------------------+------------+---------------------+---------------------+---------------------+----------+--------+\n",
      "| 0 | 1         | Manuel Gonzalez | manuel.gonzalez0@gmail.com | 816040597  | Calle Hidalgo #2502 | Comarca_Lagunera    | Comarca_Lagunera    | 62905    | Active |\n",
      "| 1 | 2         | Pedro Flores    | pedro.flores0@live.com.mx  | 6647165728 | Av. Juarez #3557    | Coahuila            | Coahuila            | 20736    | Active |\n",
      "| 2 | 3         | Sofia Garcia    | sofia.garcia0@live.com.mx  | 8715855533 | Calle Madero #2834  | Baja_California_Sur | Baja_California_Sur | 49301    | Active |\n",
      "| 3 | 4         | Miguel Torres   | miguel.torres0@gmail.com   | 6141178833 | Calle Hidalgo #4824 | Coahuila            | Coahuila            | 89688    | Active |\n",
      "| 4 | 5         | Carlos Flores   | carlos.flores0@hotmail.com | 8445477195 | Calle Madero #3679  | Sonora              | Sonora              | 56606    | Active |\n",
      "+---+-----------+-----------------+----------------------------+------------+---------------------+---------------------+---------------------+----------+--------+\n",
      "\n",
      "... showing top 5 of 3390000 rows ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Connection Configuration\n",
    "# PardoX uses 'pgwire' in Rust for a direct, driver-less connection.\n",
    "# Note: Supports standard postgres:// URI format.\n",
    "db_url = \"postgresql://betoalien:X6YGEM4CJkgR@ep-shiny-bread-78618702-pooler.us-east-2.aws.neon.tech/pleyades\"\n",
    "query = \"SELECT * FROM public.clients\"\n",
    "\n",
    "print(f\"ðŸ“¡ Connecting to: {db_url}\")\n",
    "\n",
    "try:\n",
    "    # px.read_sql executes the query and pipes the binary stream directly to HyperBlocks.\n",
    "    # No intermediate Python objects are created.\n",
    "    df_clients = px.read_sql(db_url, query)\n",
    "    \n",
    "    print(f\"âœ… SQL Ingestion Complete. Rows: {df_clients.shape[0]}\")\n",
    "    print(\"\\n--- Clients Table Preview ---\")\n",
    "    df_clients.show(5)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ SQL Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ad76e1-9fa3-4dfd-836f-a17966d580d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Creating Filter Mask (Amount > 2000.0)...\n",
      "âœ‚ï¸ Applying Filter...\n",
      "âœ… Filter Applied.\n",
      "Original Rows: 2000000\n",
      "Filtered Rows: 1201614\n",
      "\n",
      "--- High Value Transactions ---\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+------------+------------+\n",
      "| # | transaction_id | client_id |      date_time      |     entity      |  category   | client_segment |  amount   | tax_rate | tax_amount | total_paid |\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+------------+------------+\n",
      "| 0 | 1873002        | 1230720   | 2020-05-18 07:05:29 | Baja_California | Sports      | VIP            | 3683.9500 | 0.1600   | 589.4300   | 4273.3800  |\n",
      "| 1 | 1873003        | 9324201   | 2020-02-29 13:42:49 | Baja_California | Home_Decor  | Inactive       | 4104.0000 | 0.1600   | 656.6400   | 4760.6400  |\n",
      "| 2 | 1873005        | 9140257   | 2020-01-17 07:58:32 | Baja_California | Electronics | Inactive       | 4362.7900 | 0.1600   | 698.0500   | 5060.8400  |\n",
      "| 3 | 1873006        | 4952383   | 2020-12-14 23:35:34 | Baja_California | Beauty      | New            | 4917.5800 | 0.1600   | 786.8100   | 5704.3900  |\n",
      "| 4 | 1873007        | 2188656   | 2020-08-03 15:13:19 | Baja_California | Electronics | Premium        | 2458.7400 | 0.1600   | 393.4000   | 2852.1400  |\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+------------+------------+\n",
      "\n",
      "[5 rows x 10 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering Data\n",
    "# 1. Create a Boolean Mask (Predicates)\n",
    "# Logic: Find all transactions where 'amount' is greater than 2000.0\n",
    "print(\"ðŸ” Creating Filter Mask (Amount > 2000.0)...\")\n",
    "high_value_mask = df_2020['amount'] > 2000.0\n",
    "\n",
    "# 2. Inspect the Mask (Optional)\n",
    "# Returns a Boolean Series\n",
    "# print(high_value_mask.head(5))\n",
    "\n",
    "# 3. Apply Filter\n",
    "# Uses the boolean mask to slice the DataFrame.\n",
    "print(\"âœ‚ï¸ Applying Filter...\")\n",
    "df_high_value = df_2020[high_value_mask]\n",
    "\n",
    "print(f\"âœ… Filter Applied.\")\n",
    "print(f\"Original Rows: {df_2020.shape[0]}\")\n",
    "print(f\"Filtered Rows: {df_high_value.shape[0]}\")\n",
    "\n",
    "print(\"\\n--- High Value Transactions ---\")\n",
    "print(df_high_value.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c87ad11-a5cc-4e4e-88e2-9d44b72db277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Computing Statistics for 2020 Sales...\n",
      "ðŸ’° Total Sales Volume: $5,004,966,018.97\n",
      "ðŸŽ« Average Ticket: $2,502.48\n",
      "ðŸš€ Largest Single Sale: $4,999.99\n",
      "ðŸ§¾ Transaction Count: 2000000\n"
     ]
    }
   ],
   "source": [
    "# Aggregations (Map-Reduce)\n",
    "# Computes statistics on columns using parallel execution.\n",
    "\n",
    "print(\"ðŸ“Š Computing Statistics for 2020 Sales...\")\n",
    "\n",
    "# Sum\n",
    "total_sales = df_2020['amount'].sum()\n",
    "print(f\"ðŸ’° Total Sales Volume: ${total_sales:,.2f}\")\n",
    "\n",
    "# Mean\n",
    "avg_ticket = df_2020['amount'].mean()\n",
    "print(f\"ðŸŽ« Average Ticket: ${avg_ticket:,.2f}\")\n",
    "\n",
    "# Max\n",
    "max_sale = df_2020['amount'].max()\n",
    "print(f\"ðŸš€ Largest Single Sale: ${max_sale:,.2f}\")\n",
    "\n",
    "# Count\n",
    "tx_count = df_2020['amount'].count()\n",
    "print(f\"ðŸ§¾ Transaction Count: {int(tx_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e67e3101-ab9f-482a-9f43-a4859686dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ˜ Connecting to NeonDB (PostgreSQL) via Rust Native Driver...\n",
      "Target DB: ...@ep-shiny-bread-78618702-pooler.us-east-2.aws.neon.tech/pleyades\n",
      "Query:     SELECT * FROM public.clients\n",
      "\n",
      "âœ… SQL Ingestion Complete.\n",
      "â±ï¸  Time:       42.1664 seconds\n",
      "ðŸ“Š Dimensions: (3390000, 9)\n",
      "\n",
      "--- Clients Data Preview ---\n",
      "+---+-----------+-----------------+----------------------------+------------+---------------------+---------------------+---------------------+----------+--------+\n",
      "| # | client_id |    full_name    |           email            |   phone    |       address       |        city         |        state        | zip_code | status |\n",
      "+---+-----------+-----------------+----------------------------+------------+---------------------+---------------------+---------------------+----------+--------+\n",
      "| 0 | 1         | Manuel Gonzalez | manuel.gonzalez0@gmail.com | 816040597  | Calle Hidalgo #2502 | Comarca_Lagunera    | Comarca_Lagunera    | 62905    | Active |\n",
      "| 1 | 2         | Pedro Flores    | pedro.flores0@live.com.mx  | 6647165728 | Av. Juarez #3557    | Coahuila            | Coahuila            | 20736    | Active |\n",
      "| 2 | 3         | Sofia Garcia    | sofia.garcia0@live.com.mx  | 8715855533 | Calle Madero #2834  | Baja_California_Sur | Baja_California_Sur | 49301    | Active |\n",
      "| 3 | 4         | Miguel Torres   | miguel.torres0@gmail.com   | 6141178833 | Calle Hidalgo #4824 | Coahuila            | Coahuila            | 89688    | Active |\n",
      "| 4 | 5         | Carlos Flores   | carlos.flores0@hotmail.com | 8445477195 | Calle Madero #3679  | Sonora              | Sonora              | 56606    | Active |\n",
      "+---+-----------+-----------------+----------------------------+------------+---------------------+---------------------+---------------------+----------+--------+\n",
      "\n",
      "[5 rows x 9 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. NATIVE SQL INGESTION (PostgreSQL)\n",
    "# ==============================================================================\n",
    "# PardoX bypasses Python drivers (psycopg2/sqlalchemy) and uses pure Rust \n",
    "# for maximum throughput and zero-copy ingestion to HyperBlocks.\n",
    "\n",
    "print(\"ðŸ˜ Connecting to NeonDB (PostgreSQL) via Rust Native Driver...\")\n",
    "\n",
    "# Connection String\n",
    "# IMPORTANT: Rust native drivers expect standard URIs.\n",
    "# Format: postgresql://user:password@host:port/dbname\n",
    "db_url = \"postgresql://betoalien:X6YGEM4CJkgR@ep-shiny-bread-78618702-pooler.us-east-2.aws.neon.tech/pleyades\"\n",
    "\n",
    "# The Query to execute\n",
    "query = \"SELECT * FROM public.clients\"\n",
    "\n",
    "# Mask password for display security\n",
    "safe_url = db_url.split('@')[1] if '@' in db_url else \"localhost\"\n",
    "print(f\"Target DB: ...@{safe_url}\")\n",
    "print(f\"Query:     {query}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXECUTION\n",
    "# ---------------------------------------------------------\n",
    "start_sql = time.time()\n",
    "\n",
    "# px.read_sql calls 'pardox_scan_sql' in the Core DLL\n",
    "df_clients = px.read_sql(db_url, query)\n",
    "\n",
    "duration_sql = time.time() - start_sql\n",
    "\n",
    "print(f\"\\nâœ… SQL Ingestion Complete.\")\n",
    "print(f\"â±ï¸  Time:       {duration_sql:.4f} seconds\")\n",
    "print(f\"ðŸ“Š Dimensions: {df_clients.shape}\")\n",
    "\n",
    "print(\"\\n--- Clients Data Preview ---\")\n",
    "print(df_clients.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b918c76b-7e40-4316-b21a-f87b27bfb0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Joining Sales (Left) with Clients (Right)...\n",
      "âœ… Join Complete.\n",
      "Merged Dimensions: (678322, 19)\n",
      "\n",
      "--- Merged Data Preview ---\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+------------+------------+-----------+----------------+-----------------------------+------------+--------------------------+---------------------+---------------------+----------+----------+\n",
      "| # | transaction_id | client_id |      date_time      |     entity      |  category   | client_segment |  amount   | tax_rate | tax_amount | total_paid | client_id |   full_name    |            email            |   phone    |         address          |        city         |        state        | zip_code |  status  |\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+------------+------------+-----------+----------------+-----------------------------+------------+--------------------------+---------------------+---------------------+----------+----------+\n",
      "| 0 | 1873002        | 1230720   | 2020-05-18 07:05:29 | Baja_California | Sports      | VIP            | 3683.9500 | 0.1600   | 589.4300   | 4273.3800  | 1230720   | Miguel Gomez   | miguel.gomez1@outlook.com   | 813709995  | Calle Hidalgo #1917      | Durango             | Durango             | 20807    | Active   |\n",
      "| 1 | 1873007        | 2188656   | 2020-08-03 15:13:19 | Baja_California | Electronics | Premium        | 2458.7400 | 0.1600   | 393.4000   | 2852.1400  | 2188656   | Juan Perez     | juan.perez2@outlook.com     | 6647260491 | Blvd. Constitucion #2810 | Nuevo_Leon          | Nuevo_Leon          | 71125    | Active   |\n",
      "| 2 | 1873009        | 1664270   | 2020-03-01 20:18:47 | Baja_California | Toys        | VIP            | 801.2500  | 0.1600   | 128.2000   | 929.4500   | 1664270   | Ana Lopez      | ana.lopez1@gmail.com        | 8714722897 | Calle Hidalgo #754       | Baja_California_Sur | Baja_California_Sur | 29229    | Active   |\n",
      "| 3 | 1873012        | 3229193   | 2020-07-28 11:22:50 | Baja_California | Clothing    | Corporate      | 1390.6600 | 0.1600   | 222.5100   | 1613.1700  | 3229193   | Patricia Lopez | patricia.lopez3@hotmail.com | 8446663471 | Calle Madero #4592       | Coahuila            | Coahuila            | 51562    | Active   |\n",
      "| 4 | 1873017        | 2205377   | 2020-04-17 19:24:29 | Baja_California | Garden      | Inactive       | 2614.1000 | 0.1600   | 418.2600   | 3032.3600  | 2205377   | Jorge Ramirez  | jorge.ramirez2@yahoo.com    | 8716944186 | Blvd. Constitucion #1626 | Coahuila            | Coahuila            | 29952    | Inactive |\n",
      "+---+----------------+-----------+---------------------+-----------------+-------------+----------------+-----------+----------+------------+------------+-----------+----------------+-----------------------------+------------+--------------------------+---------------------+---------------------+----------+----------+\n",
      "\n",
      "[5 rows x 19 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joins (In-Memory Hash Join)\n",
    "# Merges the Sales DataFrame (CSV) with the Clients DataFrame (SQL).\n",
    "\n",
    "print(\"ðŸ”— Joining Sales (Left) with Clients (Right)...\")\n",
    "\n",
    "# We join on 'client_id' present in both datasets.\n",
    "# Uses a parallelized Hash Join algorithm in Rust.\n",
    "df_merged = df_2020.join(\n",
    "    other=df_clients,\n",
    "    on=\"client_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(f\"âœ… Join Complete.\")\n",
    "print(f\"Merged Dimensions: {df_merged.shape}\")\n",
    "\n",
    "print(\"\\n--- Merged Data Preview ---\")\n",
    "# Should show columns from both sales and clients\n",
    "print(df_merged.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14737f1f-7d2f-40d3-b571-4f3e6d08935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Starting Export of 678,322 rows to CSV...\n",
      "   (Python memory remains stable thanks to Rust Streaming)\n",
      "\n",
      "âœ… EXPORT SUCCESSFUL\n",
      "   â±ï¸ Total Time:     1.7872 seconds\n",
      "   ðŸ“¦ File Size:      135.12 MB\n",
      "   âš¡ Speed:          379,537 rows/second\n",
      "   ðŸ“‚ Location:       /home/betoalienusa/Desktop/testing-projects/pardox vs duckdb/consolidated_sales_report.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "# Define the output file name\n",
    "output_file = \"consolidated_sales_report.csv\"\n",
    "\n",
    "print(f\"ðŸ’¾ Starting Export of {df_merged.shape[0]:,} rows to CSV...\")\n",
    "print(\"   (Python memory remains stable thanks to Rust Streaming)\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# TIMER START\n",
    "# ---------------------------------------------------------\n",
    "start_time = time.time()\n",
    "\n",
    "# Call to Rust Core (API 6)\n",
    "# Rust iterates over HyperBlocks and streams data directly to disk.\n",
    "success = df_merged.to_csv(output_file)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Result Validation\n",
    "if success:\n",
    "    file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "    rows_per_sec = df_merged.shape[0] / duration\n",
    "    \n",
    "    print(f\"\\nâœ… EXPORT SUCCESSFUL\")\n",
    "    print(f\"   â±ï¸ Total Time:     {duration:.4f} seconds\")\n",
    "    print(f\"   ðŸ“¦ File Size:      {file_size_mb:.2f} MB\")\n",
    "    print(f\"   âš¡ Speed:          {rows_per_sec:,.0f} rows/second\")\n",
    "    print(f\"   ðŸ“‚ Location:       {os.path.abspath(output_file)}\")\n",
    "else:\n",
    "    print(\"âŒ Something went wrong during export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c15614-13cc-42be-8370-61213e9ad163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Binary Dump (Zero-Copy) of 678,322 rows...\n",
      "\n",
      "âœ… BINARY DUMP COMPLETE (.prdx)\n",
      "   â±ï¸ Total Time:     0.4731 seconds\n",
      "   ðŸ“¦ File Size:      49.98 MB\n",
      "   âš¡ Speed:          1,433,886 rows/second\n",
      "   ðŸ“‚ Location:       /home/betoalienusa/Desktop/testing-projects/pardox vs duckdb/consolidated_sales_report.prdx\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "# Define native file name\n",
    "output_prdx = \"consolidated_sales_report.prdx\"\n",
    "\n",
    "print(f\"ðŸš€ Starting Binary Dump (Zero-Copy) of {df_merged.shape[0]:,} rows...\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PRDX TIMER\n",
    "# ---------------------------------------------------------\n",
    "start_time = time.time()\n",
    "\n",
    "# Call Rust Core (API 7)\n",
    "# This dumps raw HyperBlock memory directly to disk.\n",
    "success = df_merged.to_prdx(output_prdx)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "if success:\n",
    "    file_size_mb = os.path.getsize(output_prdx) / (1024 * 1024)\n",
    "    rows_per_sec = df_merged.shape[0] / duration\n",
    "    \n",
    "    print(f\"\\nâœ… BINARY DUMP COMPLETE (.prdx)\")\n",
    "    print(f\"   â±ï¸ Total Time:     {duration:.4f} seconds\")\n",
    "    print(f\"   ðŸ“¦ File Size:      {file_size_mb:.2f} MB\")\n",
    "    print(f\"   âš¡ Speed:          {rows_per_sec:,.0f} rows/second\")\n",
    "    print(f\"   ðŸ“‚ Location:       {os.path.abspath(output_prdx)}\")\n",
    "else:\n",
    "    print(\"âŒ Error generating PRDX file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a43be9cd-e0fd-4658-a41a-a3d3991e1494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ» Native File Verification: consolidated_sales_report.prdx\n",
      "   ðŸ“¦ File Size: 49.98 MB\n",
      "------------------------------------------------------------\n",
      "ðŸ“– Reading HEAD (First 5 rows) via Native Engine...\n",
      "\n",
      "âœ… Read Success in 0.5400 seconds.\n",
      "\n",
      "ðŸ“Œ Native Read Result (Pure Python Rendering):\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "address                  | amount  | category    | city                | client_id | client_segment | date_time           | email                       | entity          | full_name      | phone      | state               | status   | tax_amount | tax_rate | total_paid | transaction_id | zip_code\n",
      "-------------------------+---------+-------------+---------------------+-----------+----------------+---------------------+-----------------------------+-----------------+----------------+------------+---------------------+----------+------------+----------+------------+----------------+---------\n",
      "Calle Hidalgo #1917      | 3683.95 | Sports      | Durango             | 1230720   | VIP            | 2020-05-18 07:05:29 | miguel.gomez1@outlook.com   | Baja_California | Miguel Gomez   | 813709995  | Durango             | Active   | 589.43     | 0.16     | 4273.38    | 1873002        | 20807   \n",
      "Blvd. Constitucion #2810 | 2458.74 | Electronics | Nuevo_Leon          | 2188656   | Premium        | 2020-08-03 15:13:19 | juan.perez2@outlook.com     | Baja_California | Juan Perez     | 6647260491 | Nuevo_Leon          | Active   | 393.4      | 0.16     | 2852.14    | 1873007        | 71125   \n",
      "Calle Hidalgo #754       | 801.25  | Toys        | Baja_California_Sur | 1664270   | VIP            | 2020-03-01 20:18:47 | ana.lopez1@gmail.com        | Baja_California | Ana Lopez      | 8714722897 | Baja_California_Sur | Active   | 128.2      | 0.16     | 929.45     | 1873009        | 29229   \n",
      "Calle Madero #4592       | 1390.66 | Clothing    | Coahuila            | 3229193   | Corporate      | 2020-07-28 11:22:50 | patricia.lopez3@hotmail.com | Baja_California | Patricia Lopez | 8446663471 | Coahuila            | Active   | 222.51     | 0.16     | 1613.17    | 1873012        | 51562   \n",
      "Blvd. Constitucion #1626 | 2614.1  | Garden      | Coahuila            | 2205377   | Inactive       | 2020-04-17 19:24:29 | jorge.ramirez2@yahoo.com    | Baja_California | Jorge Ramirez  | 8716944186 | Coahuila            | Inactive | 418.26     | 0.16     | 3032.36    | 1873017        | 29952   \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "ðŸš€ TEST 2: Read Throughput Benchmark (Full Scan)\n",
      "   Operation: SUM(amount) over entire file\n",
      "------------------------------------------------------------\n",
      "âœ… Aggregation Result: 1,697,469,625.05\n",
      "â±ï¸  Time:             0.0163 s\n",
      "âš¡ Throughput:       3060.58 MB/s\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pardox as px\n",
    "from pardox.wrapper import lib  # Direct access to Core for Benchmarking\n",
    "\n",
    "# File to validate\n",
    "output_prdx = \"consolidated_sales_report.prdx\"\n",
    "prdx_path = os.path.abspath(output_prdx)\n",
    "\n",
    "# Visualization Utility (Pure Python - No Pandas)\n",
    "def print_pardox_table(data_list):\n",
    "    if not data_list:\n",
    "        return\n",
    "    \n",
    "    # 1. Get columns\n",
    "    columns = list(data_list[0].keys())\n",
    "    \n",
    "    # 2. Calculate dynamic column widths\n",
    "    col_widths = {col: len(col) for col in columns}\n",
    "    for row in data_list:\n",
    "        for col in columns:\n",
    "            val_len = len(str(row.get(col, \"\")))\n",
    "            if val_len > col_widths[col]:\n",
    "                col_widths[col] = val_len\n",
    "\n",
    "    # 3. Row formatting\n",
    "    def format_row(row_data):\n",
    "        return \" | \".join(f\"{str(row_data.get(col, '')).ljust(col_widths[col])}\" for col in columns)\n",
    "\n",
    "    # 4. Print Table\n",
    "    header = \" | \".join(f\"{col.ljust(col_widths[col])}\" for col in columns)\n",
    "    separator = \"-+-\".join(\"-\" * col_widths[col] for col in columns)\n",
    "    \n",
    "    print(header)\n",
    "    print(separator)\n",
    "    for row in data_list:\n",
    "        print(format_row(row))\n",
    "\n",
    "# ==============================================================================\n",
    "# START OF REAL SHOWCASE\n",
    "# ==============================================================================\n",
    "\n",
    "print(f\"ðŸ» Native File Verification: {output_prdx}\")\n",
    "if os.path.exists(prdx_path):\n",
    "    print(f\"   ðŸ“¦ File Size: {os.path.getsize(prdx_path) / (1024 * 1024):.2f} MB\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ==============================================================================\n",
    "# TEST 1: NATIVE HEAD READ (Latency Check)\n",
    "# ==============================================================================\n",
    "print(\"ðŸ“– Reading HEAD (First 5 rows) via Native Engine...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # 1. Call to PardoX (Rust Zstd -> JSON -> Python Dicts)\n",
    "    #    No Pandas involved here.\n",
    "    data = px.read_prdx(prdx_path, limit=5)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    if data:\n",
    "        print(f\"\\nâœ… Read Success in {duration:.4f} seconds.\")\n",
    "        print(\"\\nðŸ“Œ Native Read Result (Pure Python Rendering):\")\n",
    "        print(\"-\" * 120)\n",
    "        print_pardox_table(data) # <--- Using our custom visualizer\n",
    "        print(\"-\" * 120)\n",
    "    else:\n",
    "        print(\"âš ï¸ File returned empty data.\")\n",
    "\n",
    "except AttributeError:\n",
    "    print(\"âŒ Error: 'read_prdx' not found. RESTART KERNEL after editing __init__.py\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Read Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ==============================================================================\n",
    "# TEST 2: BENCHMARK (Full Scan)\n",
    "# ==============================================================================\n",
    "print(\"ðŸš€ TEST 2: Read Throughput Benchmark (Full Scan)\")\n",
    "print(\"   Operation: SUM(amount) over entire file\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Direct call to Rust Core\n",
    "total_amount = lib.pardox_column_sum(\n",
    "    prdx_path.encode('utf-8'), \n",
    "    b\"amount\"\n",
    ")\n",
    "\n",
    "duration = time.time() - start_time\n",
    "file_size_mb = os.path.getsize(prdx_path) / (1024 * 1024) if os.path.exists(prdx_path) else 0\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"âœ… Aggregation Result: {total_amount:,.2f}\")\n",
    "print(f\"â±ï¸  Time:             {duration:.4f} s\")\n",
    "print(f\"âš¡ Throughput:       {file_size_mb / duration:.2f} MB/s\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5c180bb-fbe9-47c0-b017-66c3e174797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Data Analysis & Validation (Aggregation Engine)...\n",
      "ðŸ’° Total Revenue (2020):   $5,805,760,581.36\n",
      "ðŸŽ« Average Ticket Size:   $2,902.88\n",
      "ðŸ“ˆ Highest Transaction:  $5,799.99\n",
      "ðŸ“‰ Lowest Transaction:   $11.60\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“Š Data Analysis & Validation (Aggregation Engine)...\")\n",
    "\n",
    "# 1. Summation (Total Revenue)\n",
    "# Validates that the 'total_paid' column contains the expected volume.\n",
    "total_revenue = df_2020['total_paid'].sum()\n",
    "print(f\"ðŸ’° Total Revenue (2020):   ${total_revenue:,.2f}\")\n",
    "\n",
    "# 2. Averages (Mean)\n",
    "# Calculates the average ticket size.\n",
    "avg_ticket = df_2020['total_paid'].mean()\n",
    "print(f\"ðŸŽ« Average Ticket Size:   ${avg_ticket:,.2f}\")\n",
    "\n",
    "# 3. Extremes (Min/Max)\n",
    "# useful for identifying outliers or data errors (e.g. negative sales).\n",
    "max_sale = df_2020['total_paid'].max()\n",
    "min_sale = df_2020['total_paid'].min()\n",
    "print(f\"ðŸ“ˆ Highest Transaction:  ${max_sale:,.2f}\")\n",
    "print(f\"ðŸ“‰ Lowest Transaction:   ${min_sale:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cae49384-509a-4f2a-881e-3d4242edfd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma Statistical Insights...\n",
      "ðŸ“‰ Sales Volatility (StdDev): $1,670.08\n",
      "ðŸ“¦ Total Records Processed: 2,000,000\n"
     ]
    }
   ],
   "source": [
    "print(\"sigma Statistical Insights...\")\n",
    "\n",
    "# 1. Standard Deviation\n",
    "# High deviation implies volatile sales; Low implies consistent pricing.\n",
    "volatility = df_2020['total_paid'].std()\n",
    "print(f\"ðŸ“‰ Sales Volatility (StdDev): ${volatility:,.2f}\")\n",
    "\n",
    "# 2. Record Count\n",
    "# Verifies the total number of processed records after cleaning.\n",
    "total_records = df_2020['total_paid'].count()\n",
    "print(f\"ðŸ“¦ Total Records Processed: {total_records:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2c2c9-7011-468b-9138-c2a05d260a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
