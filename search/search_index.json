{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to PardoX","text":"<p>The Speed of Rust. The Simplicity of Python.</p> <p>PardoX is a high-performance DataFrame engine designed for modern data engineering. It combines the safety and speed of a Rust Core with the ease of use of a Python SDK, allowing you to process massive datasets efficiently without learning a new language.</p>"},{"location":"#why-pardox","title":"\ud83d\ude80 Why PardoX?","text":"<ul> <li>Zero-Copy Architecture: Data is loaded directly into memory-mapped buffers.</li> <li>SIMD Acceleration: Mathematical operations utilize AVX2/NEON CPU instructions.</li> <li>Universal Compatibility: Runs natively on Windows, Linux, and MacOS (Intel &amp; Apple Silicon).</li> <li>Native Format: The <code>.prdx</code> binary format allows for instant data persistence.</li> </ul>"},{"location":"#documentation-modules","title":"\ud83d\udcda Documentation Modules","text":"<p>Select a topic to start building faster pipelines:</p>"},{"location":"#getting-started","title":"\ud83c\udfc1 Getting Started","text":"<ul> <li>Installation - Setup guide for Windows, Linux, and Mac.</li> <li>Quick Start - Build your first ETL pipeline in 5 minutes.</li> </ul>"},{"location":"#user-guide","title":"\ud83d\udcd8 User Guide","text":"<ul> <li>Input / Output - Learn about the multi-threaded CSV reader and SQL engine.</li> <li>Data Mutation - Perform vectorized arithmetic and data cleaning.</li> <li>Aggregations - Extract business insights and statistical metrics.</li> </ul>"},{"location":"#api-reference","title":"\u2699\ufe0f API Reference","text":"<ul> <li>Full Reference - Detailed documentation of classes and functions.</li> </ul>"},{"location":"#examples-notebooks","title":"\ud83d\udcd3 Examples &amp; Notebooks","text":"<ul> <li>Jupyter Notebooks - Interactive examples and tutorials showcasing PardoX capabilities, including the v0.1 Beta Showcase with real-world ETL scenarios.</li> <li>Benchmark Scripts - Production-ready example for processing 640 million rows and transforming data into <code>.prdx</code> format, demonstrating real-world performance at scale.</li> </ul>"},{"location":"#installation","title":"\ud83d\udce6 Installation","text":"<p>Get started immediately via pip:</p> <pre><code>pip install pardox\n</code></pre> <p> Open Source Project distributed under the MIT License. </p> <p> More info: www.pardox.io </p>"},{"location":"reference/","title":"API Reference","text":"<p>This document details the classes and functions exposed by the PardoX Python SDK.</p>"},{"location":"reference/#top-level-functions","title":"Top-Level Functions","text":""},{"location":"reference/#read_csv","title":"<code>read_csv</code>","text":"<p>Reads a Comma Separated Value (CSV) file into a DataFrame using the multi-threaded Rust engine.</p> <pre><code>def read_csv(path: str, has_headers: bool = True) -&gt; DataFrame\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>path</code> <code>str</code> Path to the .csv file. <code>has_headers</code> <code>bool</code> Whether the first row contains column names. Default: <code>True</code>. <p>Returns: <code>DataFrame</code></p>"},{"location":"reference/#read_sql","title":"<code>read_sql</code>","text":"<p>Executes a SQL query against a Postgres database and loads the result directly.</p> <pre><code>def read_sql(connection_string: str, query: str) -&gt; DataFrame\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>connection_string</code> <code>str</code> URI format: <code>postgres://user:pass@host:port/db</code> <code>query</code> <code>str</code> The SQL SELECT statement to execute. <p>Returns: <code>DataFrame</code></p>"},{"location":"reference/#read_prdx","title":"<code>read_prdx</code>","text":"<p>Loads a native PardoX binary file (<code>.prdx</code>).</p> <pre><code>def read_prdx(path: str) -&gt; DataFrame\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>path</code> <code>str</code> Path to the .prdx file. <p>Returns: <code>DataFrame</code></p>"},{"location":"reference/#from_arrow","title":"<code>from_arrow</code>","text":"<p>Zero-Copy conversion from a PyArrow Table.</p> <pre><code>def from_arrow(table: pyarrow.Table) -&gt; DataFrame\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>table</code> <code>pyarrow.Table</code> PyArrow Table to convert. <p>Returns: <code>DataFrame</code></p>"},{"location":"reference/#class-dataframe","title":"Class: <code>DataFrame</code>","text":"<p>The main data structure holding the HyperBlock memory manager.</p>"},{"location":"reference/#properties","title":"Properties","text":"<ul> <li><code>shape</code>: Returns a tuple <code>(rows, cols)</code> representing the dimensions.</li> <li><code>columns</code>: Returns a list of column names.</li> </ul>"},{"location":"reference/#methods","title":"Methods","text":""},{"location":"reference/#headn5","title":"<code>head(n=5)</code>","text":"<p>Returns the first <code>n</code> rows as a list of dictionaries. Useful for inspection.</p> <pre><code>df.head(10)  # Show first 10 rows\n</code></pre>"},{"location":"reference/#tailn5","title":"<code>tail(n=5)</code>","text":"<p>Returns the last <code>n</code> rows as a list of dictionaries.</p> <pre><code>df.tail(10)  # Show last 10 rows\n</code></pre>"},{"location":"reference/#to_prdxpath","title":"<code>to_prdx(path)</code>","text":"<p>Saves the current DataFrame state to a binary file.</p> <pre><code>df.to_prdx(\"output.prdx\")\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>path</code> <code>str</code> Path to save the .prdx file."},{"location":"reference/#fillnavalue","title":"<code>fillna(value)</code>","text":"<p>Fills NaN / null values in all compatible columns with the given scalar.</p> <pre><code>df.fillna(0.0)  # Replace all nulls with 0\n</code></pre> <p>Current Limitation</p> <p>Currently supports filling numeric columns with float values.</p> <p>Parameters:</p> Parameter Type Description <code>value</code> <code>float</code> The value to replace nulls with."},{"location":"reference/#class-series","title":"Class: <code>Series</code>","text":"<p>Represents a single column within a DataFrame. Returned when selecting a column (e.g., <code>df['price']</code>).</p>"},{"location":"reference/#arithmetic","title":"Arithmetic","text":"<p>Supported operators: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code></p> <p>Operations are vectorized (SIMD) and return a new Series or modify in-place if assigned back.</p> <pre><code># Vector arithmetic\ndf['total'] = df['price'] * df['quantity']\ndf['tax'] = df['total'] * 0.16\n</code></pre>"},{"location":"reference/#aggregations","title":"Aggregations","text":""},{"location":"reference/#sum","title":"<code>sum()</code>","text":"<p>Returns the sum of all values.</p> <pre><code>total = df['amount'].sum()\n</code></pre> <p>Returns: <code>float</code></p>"},{"location":"reference/#mean","title":"<code>mean()</code>","text":"<p>Returns the arithmetic average.</p> <pre><code>average = df['amount'].mean()\n</code></pre> <p>Returns: <code>float</code></p>"},{"location":"reference/#min","title":"<code>min()</code>","text":"<p>Returns the minimum value.</p> <pre><code>lowest = df['amount'].min()\n</code></pre> <p>Returns: <code>float</code></p>"},{"location":"reference/#max","title":"<code>max()</code>","text":"<p>Returns the maximum value.</p> <pre><code>highest = df['amount'].max()\n</code></pre> <p>Returns: <code>float</code></p>"},{"location":"reference/#std","title":"<code>std()</code>","text":"<p>Returns the standard deviation (population).</p> <pre><code>volatility = df['amount'].std()\n</code></pre> <p>Returns: <code>float</code></p>"},{"location":"reference/#count","title":"<code>count()</code>","text":"<p>Returns the count of non-null values.</p> <pre><code>valid_count = df['amount'].count()\n</code></pre> <p>Returns: <code>int</code></p>"},{"location":"reference/#transformations","title":"Transformations","text":""},{"location":"reference/#rounddecimals","title":"<code>round(decimals)</code>","text":"<p>Rounds values to the specified number of decimal places in-place.</p> <pre><code>df['price'].round(2)  # Round to 2 decimals\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>decimals</code> <code>int</code> Number of decimal places."},{"location":"guide/aggregations/","title":"Aggregations &amp; Analytics","text":"<p>Once data is loaded and cleaned, the next step is extracting insights. PardoX provides a suite of Analytical Kernels that compute summary statistics over entire columns instantly.</p> <p>Unlike iterating through a list in Python (which is slow), PardoX aggregations run entirely in native machine code, leveraging CPU parallelism to scan memory buffers at maximum bandwidth.</p>"},{"location":"guide/aggregations/#1-basic-metrics","title":"1. Basic Metrics","text":"<p>You can access aggregation methods directly on any numeric <code>Series</code>.</p>"},{"location":"guide/aggregations/#summation-sum","title":"Summation (<code>sum</code>)","text":"<p>Calculates the total sum of values in the column.</p> <pre><code># Calculate Total Revenue\ntotal_revenue = df['amount'].sum()\nprint(f\"Total: ${total_revenue}\")\n</code></pre>"},{"location":"guide/aggregations/#averages-mean","title":"Averages (<code>mean</code>)","text":"<p>Calculates the arithmetic mean.</p> <pre><code># Calculate Average Transaction Size\navg_ticket = df['amount'].mean()\n</code></pre>"},{"location":"guide/aggregations/#extremes-min-max","title":"Extremes (<code>min</code> / <code>max</code>)","text":"<p>Finds the lowest and highest values in the dataset. Useful for range detection and outlier identification.</p> <pre><code>highest_sale = df['amount'].max()\nlowest_sale  = df['amount'].min()\n</code></pre>"},{"location":"guide/aggregations/#2-statistical-analysis","title":"2. Statistical Analysis","text":"<p>PardoX v0.1 includes kernels for statistical dispersion and counting.</p>"},{"location":"guide/aggregations/#standard-deviation-std","title":"Standard Deviation (<code>std</code>)","text":"<p>Measures the amount of variation or dispersion of a set of values.</p> <p>Interpretation</p> <ul> <li>Low std: Values are close to the mean.</li> <li>High std: Values are spread out over a wider range.</li> </ul> <pre><code># Analyze Sales Volatility\nvolatility = df['amount'].std()\n</code></pre>"},{"location":"guide/aggregations/#counting-count","title":"Counting (<code>count</code>)","text":"<p>Returns the number of valid (non-null) entries in the column. This is different from the DataFrame shape, as it excludes missing values.</p> <pre><code>valid_transactions = df['transaction_id'].count()\n</code></pre>"},{"location":"guide/aggregations/#3-handling-null-values","title":"3. Handling Null Values","text":"<p>PardoX aggregations are Null-Aware.</p> <p>Null Handling Strategy</p> <ul> <li>Skip Strategy: By default, all aggregation functions ignore null / NaN values. They calculate the metric based only on valid data points.</li> <li>Consistency: This matches the behavior of SQL and other major DataFrame libraries.</li> </ul>"},{"location":"guide/aggregations/#4-performance-vs-python","title":"4. Performance vs Python","text":"<p>Why use <code>df['col'].sum()</code> instead of Python's built-in <code>sum()</code>?</p> Method Mechanism Speed (10M rows) Python <code>sum(df['col'])</code> Iterates objects one by one ~1.5s PardoX <code>.sum()</code> SIMD Vectorized Accumulator ~0.02s <p>Under the Hood</p> <p>When you call <code>.sum()</code>, PardoX passes the memory pointer to a Rust function that uses AVX2 instructions to add 4 to 8 numbers simultaneously per CPU cycle, without ever converting the data back to Python objects.</p>"},{"location":"guide/aggregations/#5-groupby-operations-roadmap","title":"5. GroupBy Operations (Roadmap)","text":"<p>Current Status (v0.1 Beta): PardoX currently supports global aggregations (reducing the entire column to a scalar).</p> <p>Coming in v0.2</p> <p>We are actively developing the Split-Apply-Combine engine to support:</p> <pre><code># COMING SOON in v0.2\ndf.groupby('region').sum('amount')\n</code></pre> <p>Workaround</p> <p>For now, you can filter datasets using boolean masks (coming in v0.1.5) or perform global analysis on subsets.</p>"},{"location":"guide/io/","title":"Input / Output Operations","text":"<p>The bottleneck in most data pipelines is not calculation, but IO (Input/Output). PardoX solves this by moving data ingestion entirely to the Rust core, bypassing Python's slow file handling and object creation overhead.</p>"},{"location":"guide/io/#1-csv-files-text-data","title":"1. CSV Files (Text Data)","text":"<p>PardoX features a multi-threaded CSV reader. Instead of reading line-by-line like standard Python libraries, PardoX memory-maps the file and uses parallel workers to parse chunks simultaneously.</p>"},{"location":"guide/io/#basic-usage","title":"Basic Usage","text":"<pre><code>import pardox as px\n\n# Automatically detects headers and infers schema\ndf = px.read_csv(\"dataset.csv\")\n</code></pre>"},{"location":"guide/io/#how-it-works","title":"How it works","text":"<p>Intelligent Type Inference</p> <p>The engine scans the first N rows to determine if a column is Integer, Float, or String.</p> <p>Parallel Parsing</p> <p>The file is split into logical blocks, and multiple CPU cores parse them concurrently.</p> <p>Fail-Fast Error Handling</p> <p>If a row is malformed, PardoX will report the error immediately rather than silently corrupting data.</p>"},{"location":"guide/io/#2-native-sql-database-ingestion","title":"2. Native SQL (Database Ingestion)","text":"<p>Load data directly from SQL databases without using Python drivers (like <code>psycopg2</code> or <code>sqlalchemy</code>) as intermediaries. PardoX connects to the database at the Rust level, fetches the binary stream, and constructs the DataFrame in memory.</p>"},{"location":"guide/io/#usage","title":"Usage","text":"<p>The <code>read_sql</code> function requires a standard connection string and a SQL query.</p> <pre><code># Format: postgres://user:password@host:port/database\nconn_str = \"postgres://admin:secret@localhost:5432/analytics_db\"\n\nquery = \"\"\"\n    SELECT id, amount, date \n    FROM sales \n    WHERE region = 'US-West'\n\"\"\"\n\n# Executes query and returns PardoX DataFrame\ndf = px.read_sql(conn_str, query)\n</code></pre> <p>Performance Note</p> <p>This method is significantly faster than <code>pandas.read_sql</code> because it avoids converting SQL types to Python Objects (<code>PyObject</code>) before converting them again to internal arrays.</p>"},{"location":"guide/io/#3-the-native-format-prdx","title":"3. The Native Format (<code>.prdx</code>)","text":"<p>The PRDX format is the native binary representation of a PardoX HyperBlock. It is designed for instant persistence.</p> <p>Key Features</p> <ul> <li>No Serialization Overhead: Unlike CSV or JSON, saving to <code>.prdx</code> is effectively a direct memory dump to disk.</li> <li>Memory Mapping: Reading a <code>.prdx</code> file leverages OS-level memory mapping, allowing near-instant access to data without CPU-intensive parsing.</li> </ul>"},{"location":"guide/io/#saving-to-disk","title":"Saving to Disk","text":"<pre><code># Persist the current state of the DataFrame\ndf.to_prdx(\"backup_data.prdx\")\n</code></pre>"},{"location":"guide/io/#loading-from-disk","title":"Loading from Disk","text":"<pre><code># Load instantly\ndf_restored = px.read_prdx(\"backup_data.prdx\")\n</code></pre> <p>Benchmark</p> <p>In tests with 10GB datasets, reading a <code>.prdx</code> file achieves throughputs of 4.6 GB/s, limited only by the speed of the NVMe SSD.</p>"},{"location":"guide/io/#4-apache-arrow-bridge","title":"4. Apache Arrow Bridge","text":"<p>PardoX is designed to play well with others. If you have data in PyArrow, you can convert it to PardoX with zero-copy overhead (passing memory pointers).</p> <pre><code>import pyarrow as pa\nimport pardox as px\n\n# Assuming you have a PyArrow Table\narrow_table = pa.Table.from_pydict({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n\n# Convert to PardoX DataFrame\ndf = px.from_arrow(arrow_table)\n</code></pre> <p>Interoperability</p> <p>This bridge allows seamless integration with the Arrow ecosystem, including Polars, DuckDB, and Apache Spark.</p>"},{"location":"guide/mutation/","title":"Data Mutation &amp; Arithmetic","text":"<p>PardoX is designed for High-Performance Compute. Unlike traditional libraries that often copy data during operations, PardoX performs arithmetic and transformations directly on the underlying memory buffers using Rust's safe concurrency and SIMD (Single Instruction, Multiple Data) instructions.</p>"},{"location":"guide/mutation/#1-column-selection","title":"1. Column Selection","text":"<p>You can select a column from a DataFrame using the standard bracket notation. This returns a <code>Series</code> object, which is a lightweight wrapper around the Rust column pointer.</p> <pre><code># Select a single column\nprices = df['price']\n\n# Check the type\nprint(type(prices))  # &lt;class 'pardox.series.Series'&gt;\n</code></pre> <p>Zero-Copy Access</p> <p>Column selection returns a view, not a copy. Modifications affect the original DataFrame.</p>"},{"location":"guide/mutation/#2-vectorized-arithmetic","title":"2. Vectorized Arithmetic","text":"<p>PardoX bypasses the Python interpreter for mathematical operations. When you add, subtract, multiply, or divide columns, the instruction is sent to the Rust engine, which processes the arrays in parallel blocks.</p>"},{"location":"guide/mutation/#basic-operations","title":"Basic Operations","text":"<p>Supported operators: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code></p> <pre><code># Vector vs Vector\n# Multiplies 'price' * 'quantity' for all rows instantly\ndf['total'] = df['price'] * df['quantity']\n\n# Calculate Tax (Vector * Scalar)\n# PardoX automatically broadcasts the scalar (0.16) to all rows\ndf['tax'] = df['total'] * 0.16\n\n# Complex expressions\ndf['final_total'] = (df['total'] + df['tax']) - df['discount']\n</code></pre> <p>SIMD Acceleration</p> <p>PardoX uses AVX2 (on Intel/AMD) and NEON (on Apple Silicon) instructions. This means the CPU processes 4 to 8 numbers in a single clock cycle, resulting in speedups of 5x to 20x compared to pure Python loops.</p>"},{"location":"guide/mutation/#3-creating-new-columns","title":"3. Creating New Columns","text":"<p>You can assign the result of an operation to a new key in the DataFrame. This allocates new memory in the HyperBlock efficiently.</p> <pre><code># Create a boolean flag (stored as 0.0 or 1.0 for now)\n# (Comparison operators coming in v0.2)\ndf['is_expensive'] = df['price'] * 0.0  # Placeholder initialization\n</code></pre> <p>Memory Allocation</p> <p>New columns are allocated efficiently within the Rust HyperBlock, maintaining cache locality.</p>"},{"location":"guide/mutation/#4-data-hygiene-cleaning","title":"4. Data Hygiene (Cleaning)","text":"<p>Real-world data is messy. PardoX provides optimized kernels for cleaning data in-place (modifying the existing buffer without creating a copy).</p>"},{"location":"guide/mutation/#fillnavalue","title":"<code>fillna(value)</code>","text":"<p>Fills missing (<code>NaN</code> or <code>null</code>) values with a specified scalar.</p> <pre><code># Replace all nulls in 'age' with 0\ndf.fillna(0.0) \n\n# Note: In v0.1, fillna() applies to the entire DataFrame or specific numeric logic.\n# Future versions will support column-specific fillna.\n</code></pre> <p>In-Place Operation</p> <p>No need to reassign: <code>df.fillna(0.0)</code> modifies the DataFrame directly.</p>"},{"location":"guide/mutation/#rounddecimals","title":"<code>round(decimals)</code>","text":"<p>Rounds floating-point numbers to a specific precision.</p> <pre><code># Round all numeric columns to 2 decimal places\ndf.round(2)\n</code></pre>"},{"location":"guide/mutation/#5-performance-best-practices","title":"5. Performance Best Practices","text":"<p>To get the most out of the Mutation Engine:</p> <p>Best Practices</p> <ul> <li>Chain Operations: Python handles the operator precedence, but keep expressions vector-based.</li> <li>Avoid Loops: Never iterate over rows with a <code>for</code> loop (e.g., <code>for row in df:</code>). This kills performance. Always use column arithmetic.</li> <li>In-Place is Faster: Functions like <code>fillna()</code> modify the data directly. You don't need to do <code>df = df.fillna()</code>.</li> </ul>"},{"location":"guide/mutation/#example-the-right-way-vs-the-wrong-way","title":"Example: The Right Way vs. The Wrong Way","text":"<pre><code># \u274c SLOW (Python Loop)\nfor i in range(len(df)):\n    df['new'][i] = df['a'][i] + df['b'][i]\n\n# \u2705 FAST (PardoX SIMD)\ndf['new'] = df['a'] + df['b']\n</code></pre> <p>Performance Impact</p> <p>The vectorized approach is 100x to 1000x faster than Python loops for large datasets.</p>"},{"location":"started/installation/","title":"Installation","text":"<p>PardoX is available on PyPI and supports Windows, Linux, and MacOS (Intel &amp; Apple Silicon).</p>"},{"location":"started/installation/#via-pip","title":"via Pip","text":"<p>The easiest way to install PardoX is via pip:</p> <pre><code>pip install pardox\n</code></pre>"},{"location":"started/installation/#system-requirements","title":"System Requirements","text":"OS Architecture Status Linux x86_64 \u2705 Stable Windows x86_64 \u2705 Stable MacOS ARM64 (M1/M2/M3) \u2705 Stable MacOS x86_64 (Intel) \u2705 Stable <p>Dependencies</p> <p>PardoX requires Python 3.8 or higher. No Rust compiler is needed as binaries are pre-packaged.</p>"},{"location":"started/quickstart/","title":"Quick Start","text":"<p>This guide will walk you through a complete high-performance data pipeline: loading data, cleaning it, performing vector calculations, and saving it in the native PRDX format.</p>"},{"location":"started/quickstart/#the-hello-world-of-data","title":"The \"Hello World\" of Data","text":"<p>Copy and paste the following code into a Python script (e.g., <code>main.py</code>) or a Jupyter Notebook.</p> <pre><code>import pardox as px\n\n# 1. Ingest Data (Zero-Copy)\n# PardoX automatically detects headers and infers data types.\nprint(\"Loading data...\")\ndf = px.read_csv(\"sales_data.csv\")\n\nprint(f\"Loaded {df.shape[0]} rows.\")\n\n# 2. Data Hygiene\n# Fill missing values in numeric columns instantly.\n# This operation happens in-place within the Rust HyperBlock.\ndf.fillna(0.0)\n\n# 3. Feature Engineering (SIMD Accelerated)\n# Create a new column 'total_amount' by multiplying price * quantity.\n# PardoX executes this using AVX2/NEON instructions.\ndf['total_amount'] = df['price'] * df['quantity']\n\n# 4. Aggregations &amp; Analysis\n# Calculate business metrics immediately.\nrevenue = df['total_amount'].sum()\navg_ticket = df['total_amount'].mean()\n\nprint(\"-\" * 30)\nprint(f\"Total Revenue: ${revenue:,.2f}\")\nprint(f\"Avg Ticket:    ${avg_ticket:,.2f}\")\nprint(\"-\" * 30)\n\n# 5. Persist to Disk\n# Save the processed dataframe to the ultra-fast .prdx binary format.\n# This format is optimized for memory mapping and instant loading.\ndf.to_prdx(\"sales_processed.prdx\")\nprint(\"Data saved to 'sales_processed.prdx'\")\n</code></pre>"},{"location":"started/quickstart/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":""},{"location":"started/quickstart/#1-ingestion-read_csv","title":"1. Ingestion (<code>read_csv</code>)","text":"<p>Unlike standard libraries that parse text line-by-line in Python, PardoX spawns a Rust Thread Pool to parse chunks of the CSV in parallel.</p> <p>Zero-Copy Architecture</p> <p>No intermediate Python objects are created during ingestion. Data flows directly from disk into Rust-managed memory.</p>"},{"location":"started/quickstart/#2-mutation-fillna","title":"2. Mutation (<code>fillna</code>)","text":"<p>Data cleaning operations are mutations. They modify the memory buffer directly. There is no need to reassign the variable (e.g., <code>df = df.fillna()</code> is not needed, just <code>df.fillna()</code>).</p> <p>In-Place Operations</p> <p>All mutation operations happen in the Rust HyperBlock, avoiding expensive Python allocations.</p>"},{"location":"started/quickstart/#3-vectorization-dfa-dfb","title":"3. Vectorization (<code>df['a'] * df['b']</code>)","text":"<p>Mathematical operations do not happen in the Python interpreter. The wrapper sends pointers to the Rust engine, which uses SIMD (Single Instruction, Multiple Data) to process thousands of rows per CPU cycle.</p> <p>SIMD Acceleration</p> <p>PardoX automatically leverages AVX2 (Intel/AMD) or NEON (ARM) instructions for maximum throughput.</p>"},{"location":"started/quickstart/#4-serialization-to_prdx","title":"4. Serialization (<code>to_prdx</code>)","text":"<p>The <code>.prdx</code> format is a custom binary layout. It allows PardoX to \"snapshot\" the memory state to disk. Reading a <code>.prdx</code> file is typically 5x to 10x faster than reading a CSV or Parquet file.</p> <p>Performance Benchmark</p> <p>Loading a 2GB dataset: CSV ~8s, Parquet ~3s, PRDX ~0.5s</p>"}]}